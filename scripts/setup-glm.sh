#!/bin/bash
# ============================================
# GLM-4.7-Flash Setup Script for Riyadh Guide
# Model: unsloth/GLM-4.7-Flash-GGUF
# ============================================

echo "ðŸš€ GLM-4.7-Flash Setup for Riyadh Tourism Platform"
echo "=================================================="

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed!"
    echo "ðŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    echo "âœ… Ollama installed successfully!"
fi

# Check if Ollama is running
if ! pgrep -x "ollama" > /dev/null; then
    echo "ðŸ”„ Starting Ollama service..."
    ollama serve &
    sleep 3
fi

echo ""
echo "ðŸ“¦ Downloading GLM-4.7-Flash model..."
echo "   This is a 30B-A3B MoE (Mixture of Experts) model"
echo "   It may take some time depending on your internet speed..."
echo ""

# Download the model from Hugging Face via Ollama
# Using Q4_K_M quantization for good balance of quality and size
ollama pull hf.co/unsloth/GLM-4.7-Flash-GGUF:Q4_K_M

# Create an alias for easier usage
echo ""
echo "ðŸ”§ Creating model alias 'glm-4.7-flash'..."

# Create a Modelfile for the alias
cat > /tmp/Modelfile-glm << EOF
FROM hf.co/unsloth/GLM-4.7-Flash-GGUF:Q4_K_M

# Riyadh Tourism Guide System Prompt
SYSTEM """Ø£Ù†Øª Ù…Ø±Ø´Ø¯ Ø³ÙŠØ§Ø­ÙŠ Ø°ÙƒÙŠ ÙˆÙ…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©. 
Ù„Ø¯ÙŠÙƒ Ù…Ø¹Ø±ÙØ© Ø¹Ù…ÙŠÙ‚Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙÙŠØ© ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶.
ÙŠÙ…ÙƒÙ†Ùƒ:
- Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø· Ø³ÙŠØ§Ø­ÙŠØ© Ù…Ø®ØµØµØ©
- ÙˆØµÙ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
- ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙˆØ§Ù„Ù…ÙˆØ§Ø³Ù…
- Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø²ÙˆØ§Ø± Ø¨Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©

You are a smart, multilingual tour guide for Riyadh, Saudi Arabia.
You have deep knowledge of all tourist, historical, and cultural landmarks in Riyadh."""

# Optimized parameters for tourism guide tasks
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_ctx 8192
EOF

ollama create glm-4.7-flash -f /tmp/Modelfile-glm
rm /tmp/Modelfile-glm

echo ""
echo "âœ… GLM-4.7-Flash setup complete!"
echo ""
echo "ðŸ“Š Testing the model..."
ollama run glm-4.7-flash "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ù‚Ø¯Ù… Ù†ÙØ³Ùƒ ÙƒÙ…Ø±Ø´Ø¯ Ø³ÙŠØ§Ø­ÙŠ Ù„Ù„Ø±ÙŠØ§Ø¶." --verbose

echo ""
echo "=================================================="
echo "ðŸŽ‰ Setup Complete!"
echo ""
echo "Available quantizations (run if you need different size):"
echo "  - Q2_K:    ~2.5GB  (Fastest, lower quality)"
echo "  - Q4_K_M:  ~4.5GB  (Recommended, good balance)"
echo "  - Q5_K_M:  ~5.5GB  (Higher quality)"
echo "  - Q8_0:    ~8GB    (Highest quality)"
echo ""
echo "To use a different quantization:"
echo "  ollama pull hf.co/unsloth/GLM-4.7-Flash-GGUF:Q8_0"
echo ""
echo "Start the web app with: npm run dev"
echo "=================================================="
